{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dependencies and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm\n",
    "import math\n",
    "import re\n",
    "\n",
    "\n",
    "fake, non_fake  = pd.read_excel('cleaned_files/Fakeset_cleaned_165.xlsx'), pd.read_excel('cleaned_files/Non-fakeset_cleaned_318.xlsx')\n",
    "\n",
    "dataset = pd.concat([fake, non_fake])\n",
    "\n",
    "pravda_unian_set = pd.read_excel('cleaned_files/Non-fakeset.xlsx')\n",
    "\n",
    "testing_set = pravda_unian_set[(pravda_unian_set['url'].isin(dataset['url']) == False)]\n",
    "\n",
    "dataset.reset_index(np.linspace(1,len(dataset)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Creating features with propaganda-sensitive words\n",
    "\n",
    "pol_words = ['донецкая народная республика','ополченцы', 'фашисты', 'радикальной', 'незалежная', 'киевские власти', 'народный', 'савченко', 'народная', 'каратели', 'киев', 'ордо','террористы', 'боевики', 'гибридная', 'ато', 'незаконные вооруженные формирования', 'пророссийские боевики','бандформирования']\n",
    "\n",
    "def political_words(row):\n",
    "    data = row['text'].lower()\n",
    "    words = pol_words\n",
    "    for word in words:\n",
    "        if word in data:\n",
    "            row[word] = 1\n",
    "        else:\n",
    "            row[word] = 0\n",
    "    return row\n",
    "\n",
    "def build_log_scale(row):\n",
    "    scale = pow(len(row['text']), 1/10)\n",
    "    spmarks_ratio = len(re.findall('[,.?!:;\"]', row['text']))\n",
    "    score = math.log(spmarks_ratio, scale)\n",
    "    return score\n",
    "\n",
    "def build_digit_scale(row):\n",
    "    scale = pow(len(row['text']), 1/10)\n",
    "    digit_ratio = len(re.findall('(\\d{1,2})+', row['text']))\n",
    "    if digit_ratio == 0:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = math.log(digit_ratio, scale)\n",
    "    return score\n",
    "\n",
    "dataset = dataset.apply(political_words, axis=1)\n",
    "\n",
    "dataset['special_marks'] = dataset.apply(build_log_scale, axis=1)\n",
    "dataset['digit_freq'] = dataset.apply(build_digit_scale, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.loc[:,'донецкая народная республика': 'digit_freq'], \n",
    "                                                    dataset['target'], \n",
    "                                                    random_state=0)\n",
    "\n",
    "model = svm.SVC(kernel='linear', C=100).fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "auc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.85950413223140498, 'auc': 0.83594771241830057, 'test_set_accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "testing_set = testing_set.apply(political_words, axis=1)\n",
    "testing_set['special_marks'] = testing_set.apply(build_log_scale, axis=1)\n",
    "testing_set['digit_freq'] = testing_set.apply(build_digit_scale, axis=1)\n",
    "\n",
    "res = model.predict(test.loc[:,'special_marks': 'бандформирования'])\n",
    "\n",
    "'''By using only matrix of politically sensitive words and additional features, \\n\n",
    "the accuracy and auc score are much below the vectorizered model. However, the model does not overfitt data and perform\n",
    "extremely well on third party set'''\n",
    "print({'accuracy': accuracy, 'auc': auc, 'test_set_accuracy': (1-np.count_nonzero(res)/len(res))})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
